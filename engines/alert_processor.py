#!/usr/bin/env python3
# SPDX-License-Identifier: BUSL-1.1
"""
Alert Processor - SaferTrade Alert Delivery Service

Processes alerts from Redis queues and delivers them to configured channels.
Bridges the gap between alert generation and notification delivery.

PERFECTION UPGRADE v1 (2025-12-23):
- Atomic queue processing (prevents race conditions)
- Retry logic with exponential backoff for failed alerts
- Rate limiting per channel (respects Telegram/Discord API limits)
- Priority queue support (critical alerts processed first)
- Alert deduplication with TTL cache
- Database persistence for alert history
- Dead letter queue for repeatedly failed alerts
- Configurable thresholds via environment
- Comprehensive metrics for monitoring

PERFECTION UPGRADE v2 (2025-12-23):
- Redis stream publishing for delivery status monitoring
- Publishes to safertrade:alert_delivery for dashboard observability
- Enterprise-grade: full streaming integration complete

PERFECTION UPGRADE v3 (2025-12-23):
- Added VERSION constant
- Added --stats CLI mode
"""

# Version constant for tracking
ALERT_PROCESSOR_VERSION = "2.0.0"

import asyncio
import hashlib
import json
import logging
import os
import sys
import time
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional

import redis

# Load environment first
from dotenv import load_dotenv

load_dotenv("secrets/.env.runtime")

# SaferTrade imports
from shared.alert_formatter import AlertMessage, AlertType  # noqa: E402
from shared.db import connect  # noqa: E402
from shared.discord_alerts import send_discord_alert  # noqa: E402
from shared.env import load_env  # noqa: E402
from shared.logging_setup import setup_logging  # noqa: E402
from shared.paths import ROOT_DIR  # noqa: E402
from shared.telegram_alerts import send_telegram_alert  # noqa: E402

# Load environment again for compatibility
load_env(ROOT_DIR)

# Setup logging properly
setup_logging("alert_processor", ROOT_DIR)
logger = logging.getLogger("alert_processor")


class AlertProcessor:
    """
    Production-grade alert processor with retry logic, rate limiting,
    deduplication, and dead letter queue support.
    """

    def __init__(self):
        # Redis connection with proper configuration
        redis_password = os.getenv("REDIS_PASSWORD", "")
        self.redis = redis.Redis(
            host=os.getenv("REDIS_HOST", "localhost"),
            port=int(os.getenv("REDIS_PORT", 6379)),
            password=redis_password if redis_password else None,
            decode_responses=True,
            socket_timeout=10,
            socket_connect_timeout=5,
        )

        self.running = False

        # =====================================================================
        # CONFIGURABLE THRESHOLDS (via environment variables)
        # =====================================================================
        self.config = {
            # Processing intervals
            "check_interval": float(os.getenv("ALERT_CHECK_INTERVAL", "1.0")),
            "batch_size": int(os.getenv("ALERT_BATCH_SIZE", "10")),
            # Retry settings
            "max_retries": int(os.getenv("ALERT_MAX_RETRIES", "3")),
            "retry_base_delay": float(os.getenv("ALERT_RETRY_BASE_DELAY", "2.0")),
            "retry_max_delay": float(os.getenv("ALERT_RETRY_MAX_DELAY", "60.0")),
            # Rate limiting (alerts per minute per channel)
            "telegram_rate_limit": int(os.getenv("TELEGRAM_RATE_LIMIT", "20")),
            "discord_rate_limit": int(os.getenv("DISCORD_RATE_LIMIT", "30")),
            # Deduplication TTL (seconds)
            "dedup_ttl": int(os.getenv("ALERT_DEDUP_TTL", "300")),
            # Dead letter queue threshold
            "dlq_threshold": int(os.getenv("ALERT_DLQ_THRESHOLD", "5")),
            # =====================================================================
            # REDIS STREAM PUBLISHING (for dashboard observability)
            # =====================================================================
            "publish_delivery_status": os.getenv("ALERT_PUBLISH_STATUS", "true").lower()
            == "true",
            "delivery_stream": os.getenv(
                "ALERT_DELIVERY_STREAM", "safertrade:alert_delivery"
            ),
            "stream_maxlen": int(os.getenv("ALERT_STREAM_MAXLEN", "1000")),
        }

        # Queue names
        self.queues = {
            # Priority queues (processed first)
            "telegram_critical": "alerts.telegram.critical",
            "discord_critical": "alerts.discord.critical",
            # Normal queues
            "telegram": "alerts.telegram",
            "discord": "alerts.discord",
            # Dead letter queues
            "telegram_dlq": "alerts.telegram.dlq",
            "discord_dlq": "alerts.discord.dlq",
        }

        # Rate limiting tracking
        self.rate_limits = {
            "telegram": {"count": 0, "reset_time": time.time() + 60},
            "discord": {"count": 0, "reset_time": time.time() + 60},
        }

        # Statistics
        self.stats = {
            "alerts_processed": 0,
            "alerts_sent": 0,
            "alerts_failed": 0,
            "alerts_deduplicated": 0,
            "alerts_rate_limited": 0,
            "alerts_dead_lettered": 0,
            "retries_attempted": 0,
            "start_time": time.time(),
        }

        # Initialize database for alert history
        self._init_database()

        logger.info("âœ… Alert Processor initialized with production-grade features")
        logger.info(f"   Config: {json.dumps(self.config, indent=2)}")

    def _init_database(self):
        """Initialize database tables for alert history and tracking."""
        try:
            conn = connect()
            cursor = conn.cursor()

            # Alert history table
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS alert_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    channel TEXT NOT NULL,
                    alert_type TEXT,
                    severity TEXT,
                    title TEXT,
                    description TEXT,
                    alert_hash TEXT,
                    delivery_status TEXT,
                    retry_count INTEGER DEFAULT 0,
                    error_message TEXT,
                    processing_time_ms REAL
                )
            """)

            # Create indexes for efficient queries
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_alert_history_timestamp
                ON alert_history(timestamp)
            """)
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_alert_history_channel
                ON alert_history(channel, delivery_status)
            """)

            conn.commit()
            conn.close()
            logger.info("âœ… Alert history database initialized")
        except Exception as e:
            logger.error(f"Failed to initialize database: {e}")

    def _generate_alert_hash(self, alert_data: Dict) -> str:
        """Generate a hash for deduplication purposes."""
        # Use key fields for deduplication
        key_fields = {
            "type": alert_data.get("alert_type", ""),
            "title": alert_data.get("title", ""),
            "severity": alert_data.get("severity", ""),
            "chain": alert_data.get("chain", ""),
            "address": alert_data.get("address", ""),
        }
        content = json.dumps(key_fields, sort_keys=True)
        return hashlib.sha256(content.encode()).hexdigest()[:32]

    def _is_duplicate(self, alert_hash: str, channel: str) -> bool:
        """Check if alert was recently sent (deduplication)."""
        dedup_key = f"alert_dedup:{channel}:{alert_hash}"
        if self.redis.exists(dedup_key):
            self.stats["alerts_deduplicated"] += 1
            return True
        return False

    def _mark_as_sent(self, alert_hash: str, channel: str):
        """Mark alert as sent for deduplication."""
        dedup_key = f"alert_dedup:{channel}:{alert_hash}"
        self.redis.setex(dedup_key, self.config["dedup_ttl"], "1")

    def _check_rate_limit(self, channel: str) -> bool:
        """Check if we're within rate limits for this channel."""
        limit_config = self.rate_limits.get(channel)
        if not limit_config:
            return True

        current_time = time.time()

        # Reset counter if minute has passed
        if current_time >= limit_config["reset_time"]:
            limit_config["count"] = 0
            limit_config["reset_time"] = current_time + 60

        # Check against limit
        max_limit = self.config.get(f"{channel}_rate_limit", 30)
        if limit_config["count"] >= max_limit:
            self.stats["alerts_rate_limited"] += 1
            return False

        limit_config["count"] += 1
        return True

    def _calculate_retry_delay(self, retry_count: int) -> float:
        """Calculate exponential backoff delay."""
        delay = self.config["retry_base_delay"] * (2**retry_count)
        return min(delay, self.config["retry_max_delay"])

    async def start(self):
        """Start the alert processing service."""
        self.running = True
        logger.info("ðŸš¨ Alert Processor starting...")

        try:
            while self.running:
                # Process critical alerts first (priority queue)
                await self._process_queue("telegram_critical", "telegram")
                await self._process_queue("discord_critical", "discord")

                # Process normal alerts
                await self._process_queue("telegram", "telegram")
                await self._process_queue("discord", "discord")

                # Log stats periodically (every 60 seconds)
                if int(time.time()) % 60 == 0:
                    self._log_stats()

                await asyncio.sleep(self.config["check_interval"])

        except KeyboardInterrupt:
            logger.info("Alert Processor stopped by user")
        except Exception as e:
            logger.error(f"Alert Processor error: {e}", exc_info=True)
        finally:
            self.running = False
            self._log_stats()

    async def _process_queue(self, queue_name: str, channel: str) -> int:
        """Process alerts from a specific queue with atomic operations."""
        processed_count = 0
        queue_key = self.queues.get(queue_name, queue_name)

        try:
            # Get batch of alerts (use LRANGE for batch, then LPOP for each)
            alerts = self.redis.lrange(queue_key, 0, self.config["batch_size"] - 1)

            if not alerts:
                return 0

            for alert_text in alerts:
                try:
                    # Atomically remove from queue
                    self.redis.lpop(queue_key)

                    # Parse alert
                    alert_data = self._parse_alert(alert_text)

                    # Generate hash for deduplication
                    alert_hash = self._generate_alert_hash(alert_data)

                    # Check for duplicate
                    if self._is_duplicate(alert_hash, channel):
                        logger.debug(f"Skipping duplicate alert: {alert_hash[:8]}...")
                        continue

                    # Check rate limit
                    if not self._check_rate_limit(channel):
                        # Re-queue for later processing
                        self.redis.rpush(queue_key, alert_text)
                        logger.warning(f"Rate limited on {channel}, re-queued alert")
                        continue

                    # Attempt delivery with retry logic
                    start_time = time.time()
                    success, error_msg = await self._deliver_alert_with_retry(
                        alert_data, channel
                    )
                    processing_time = (time.time() - start_time) * 1000

                    # Record to database
                    self._record_alert_history(
                        channel=channel,
                        alert_data=alert_data,
                        alert_hash=alert_hash,
                        success=success,
                        error_msg=error_msg,
                        processing_time=processing_time,
                    )

                    if success:
                        self._mark_as_sent(alert_hash, channel)
                        self.stats["alerts_sent"] += 1
                        logger.info(
                            f"âœ… {channel.upper()} alert delivered ({processing_time:.0f}ms)"
                        )
                    else:
                        self.stats["alerts_failed"] += 1
                        logger.warning(
                            f"âŒ {channel.upper()} alert failed: {error_msg}"
                        )

                    self.stats["alerts_processed"] += 1
                    processed_count += 1

                except Exception as e:
                    logger.error(f"Error processing {channel} alert: {e}")
                    self.stats["alerts_failed"] += 1

        except redis.RedisError as e:
            logger.error(f"Redis error accessing {queue_name}: {e}")

        return processed_count

    def _parse_alert(self, alert_text: str) -> Dict:
        """Parse alert from string (JSON or plain text)."""
        try:
            return json.loads(alert_text)
        except json.JSONDecodeError:
            # Plain text alert
            return {
                "alert_type": "general",
                "title": "Alert",
                "description": alert_text,
                "severity": "MEDIUM",
                "timestamp": time.time(),
            }

    async def _deliver_alert_with_retry(
        self, alert_data: Dict, channel: str
    ) -> tuple[bool, Optional[str]]:
        """Deliver alert with exponential backoff retry logic."""
        max_retries = self.config["max_retries"]
        retry_count = 0
        last_error = None

        while retry_count <= max_retries:
            try:
                if channel == "telegram":
                    success = await self._send_telegram_alert(alert_data)
                elif channel == "discord":
                    success = await self._send_discord_alert(alert_data)
                else:
                    logger.warning(f"Unknown channel: {channel}")
                    return False, f"Unknown channel: {channel}"

                if success:
                    return True, None

                # Delivery returned False (not an exception)
                last_error = "Delivery returned False"

            except Exception as e:
                last_error = str(e)
                logger.warning(f"Delivery attempt {retry_count + 1} failed: {e}")

            # Retry logic
            retry_count += 1
            self.stats["retries_attempted"] += 1

            if retry_count <= max_retries:
                delay = self._calculate_retry_delay(retry_count)
                logger.info(
                    f"Retrying in {delay:.1f}s (attempt {retry_count}/{max_retries})"
                )
                await asyncio.sleep(delay)

        # All retries exhausted - move to dead letter queue
        if retry_count > self.config["dlq_threshold"]:
            self._move_to_dlq(alert_data, channel, last_error)

        return False, last_error

    async def _send_telegram_alert(self, alert_data: Dict) -> bool:
        """Send alert to Telegram."""
        try:
            if "alert_type" in alert_data and alert_data["alert_type"] != "general":
                alert_message = self._dict_to_alert_message(alert_data)
                return send_telegram_alert(
                    alert_message,
                    "free",
                    alert_data.get("severity", "MEDIUM"),
                )
            else:
                # Plain text via telegram_notifier
                from shared.telegram_notifier import telegram_notifier

                return telegram_notifier.send_message(
                    alert_data.get("description", str(alert_data))
                )
        except Exception as e:
            logger.error(f"Telegram send error: {e}")
            raise

    async def _send_discord_alert(self, alert_data: Dict) -> bool:
        """Send alert to Discord."""
        try:
            if "alert_type" in alert_data and alert_data["alert_type"] != "general":
                alert_message = self._dict_to_alert_message(alert_data)
                return send_discord_alert(
                    alert_message,
                    "free",
                    alert_data.get("severity", "MEDIUM"),
                )
            else:
                # Plain text via discord_notifier
                from shared.discord_notifier import discord_notifier

                return discord_notifier.send_message(
                    alert_data.get("description", str(alert_data))
                )
        except Exception as e:
            logger.error(f"Discord send error: {e}")
            raise

    def _dict_to_alert_message(self, alert_data: Dict[str, Any]) -> AlertMessage:
        """Convert dictionary to AlertMessage object."""
        try:
            alert_type = AlertType(alert_data.get("alert_type", "general"))
        except ValueError:
            alert_type = AlertType.GENERAL

        timestamp = alert_data.get("timestamp")
        if isinstance(timestamp, (int, float)):
            dt = datetime.fromtimestamp(timestamp, tz=timezone.utc)
        else:
            dt = datetime.now(tz=timezone.utc)

        return AlertMessage(
            alert_type=alert_type,
            title=alert_data.get("title", "Alert"),
            description=alert_data.get("description", "No description"),
            severity=alert_data.get("severity", "MEDIUM"),
            timestamp=dt,
            chain=alert_data.get("chain"),
            amount_usd=alert_data.get("amount_usd"),
            token=alert_data.get("token"),
            address=alert_data.get("address"),
            additional_data=alert_data,
            confidence=alert_data.get("confidence"),
            estimated_impact=alert_data.get("estimated_impact"),
        )

    def _move_to_dlq(self, alert_data: Dict, channel: str, error: str):
        """Move failed alert to dead letter queue."""
        dlq_key = self.queues.get(f"{channel}_dlq", f"alerts.{channel}.dlq")
        dlq_entry = {
            "original_alert": alert_data,
            "error": error,
            "failed_at": datetime.now(tz=timezone.utc).isoformat(),
            "channel": channel,
        }
        self.redis.rpush(dlq_key, json.dumps(dlq_entry))
        self.stats["alerts_dead_lettered"] += 1
        logger.warning(f"Alert moved to DLQ: {dlq_key}")

    def _record_alert_history(
        self,
        channel: str,
        alert_data: Dict,
        alert_hash: str,
        success: bool,
        error_msg: Optional[str],
        processing_time: float,
    ):
        """Record alert delivery to database for history/audit."""
        try:
            conn = connect()
            cursor = conn.cursor()

            cursor.execute(
                """
                INSERT INTO alert_history
                (channel, alert_type, severity, title, description, alert_hash,
                 delivery_status, error_message, processing_time_ms)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                (
                    channel,
                    alert_data.get("alert_type", "unknown"),
                    alert_data.get("severity", "MEDIUM"),
                    alert_data.get("title", "")[:200],
                    alert_data.get("description", "")[:500],
                    alert_hash,
                    "delivered" if success else "failed",
                    error_msg[:500] if error_msg else None,
                    processing_time,
                ),
            )

            conn.commit()
            conn.close()
        except Exception as e:
            logger.error(f"Failed to record alert history: {e}")

        # Publish to Redis stream for real-time observability
        self._publish_delivery_status(
            channel=channel,
            alert_data=alert_data,
            alert_hash=alert_hash,
            success=success,
            error_msg=error_msg,
            processing_time=processing_time,
        )

    def _publish_delivery_status(
        self,
        channel: str,
        alert_data: Dict,
        alert_hash: str,
        success: bool,
        error_msg: Optional[str],
        processing_time: float,
    ):
        """Publish delivery status to Redis stream for dashboard observability.

        Publishes to safertrade:alert_delivery stream so dashboards can:
        - Show real-time delivery success/failure rates
        - Track delivery latency metrics
        - Alert on delivery failures
        """
        if not self.config.get("publish_delivery_status", True):
            return

        try:
            payload = {
                "source": "alert_processor",
                "type": "delivery_status",
                "channel": channel,
                "alert_type": str(alert_data.get("alert_type", "unknown")),
                "severity": str(alert_data.get("severity", "MEDIUM")),
                "alert_hash": alert_hash,
                "status": "delivered" if success else "failed",
                "processing_time_ms": str(round(processing_time, 2)),
                "timestamp": datetime.now(timezone.utc).isoformat(),
            }

            if error_msg:
                payload["error"] = str(error_msg)[:200]

            self.redis.xadd(
                self.config["delivery_stream"],
                payload,
                maxlen=self.config.get("stream_maxlen", 1000),
                approximate=True,
            )

            logger.debug(
                f"Published delivery status to {self.config['delivery_stream']}: "
                f"{channel} {'âœ…' if success else 'âŒ'}"
            )

        except redis.RedisError as e:
            logger.debug(f"Failed to publish delivery status: {e}")
        except Exception as e:
            logger.debug(f"Unexpected error publishing delivery status: {e}")

    def _log_stats(self):
        """Log current processing statistics."""
        uptime = time.time() - self.stats["start_time"]
        rate = self.stats["alerts_processed"] / max(1, uptime) * 60

        logger.info(
            f"ðŸ“Š Stats: processed={self.stats['alerts_processed']} | "
            f"sent={self.stats['alerts_sent']} | "
            f"failed={self.stats['alerts_failed']} | "
            f"dedup={self.stats['alerts_deduplicated']} | "
            f"rate_limited={self.stats['alerts_rate_limited']} | "
            f"dlq={self.stats['alerts_dead_lettered']} | "
            f"retries={self.stats['retries_attempted']} | "
            f"rate={rate:.1f}/min"
        )

    def get_stats(self) -> Dict[str, Any]:
        """Get comprehensive processing statistics."""
        uptime = time.time() - self.stats["start_time"]
        success_rate = (
            self.stats["alerts_sent"] / max(1, self.stats["alerts_processed"])
        ) * 100

        return {
            **self.stats,
            "uptime_seconds": uptime,
            "success_rate": round(success_rate, 1),
            "alerts_per_minute": round(
                self.stats["alerts_processed"] / max(1, uptime) * 60, 2
            ),
            "queue_sizes": {
                "telegram": self.redis.llen(self.queues["telegram"]),
                "telegram_critical": self.redis.llen(self.queues["telegram_critical"]),
                "discord": self.redis.llen(self.queues["discord"]),
                "discord_critical": self.redis.llen(self.queues["discord_critical"]),
                "telegram_dlq": self.redis.llen(self.queues["telegram_dlq"]),
                "discord_dlq": self.redis.llen(self.queues["discord_dlq"]),
            },
        }

    def health(self) -> Dict[str, Any]:
        """Health check endpoint data."""
        try:
            self.redis.ping()
            redis_ok = True
        except Exception:
            redis_ok = False

        return {
            "engine": "alert_processor",
            "status": "healthy" if redis_ok else "unhealthy",
            "redis_connected": redis_ok,
            "queues": {
                "telegram": self.redis.llen(self.queues["telegram"])
                if redis_ok
                else -1,
                "discord": self.redis.llen(self.queues["discord"]) if redis_ok else -1,
            },
            "config": self.config,
            "timestamp": datetime.now(tz=timezone.utc).isoformat(),
        }

    def stop(self):
        """Stop the alert processor."""
        self.running = False
        logger.info("Alert Processor stop requested")


async def main():
    """Main entry point."""
    # Lightweight health mode
    if len(sys.argv) > 1 and sys.argv[1] == "--health":
        try:
            processor = AlertProcessor()
            health = processor.health()
            health["version"] = ALERT_PROCESSOR_VERSION
            print(json.dumps(health, indent=2))
            return
        except Exception as e:
            print(
                json.dumps(
                    {
                        "engine": "alert_processor",
                        "version": ALERT_PROCESSOR_VERSION,
                        "status": "unhealthy",
                        "error": str(e),
                        "timestamp": datetime.now(tz=timezone.utc).isoformat(),
                    }
                )
            )
            return

    # Stats mode
    if len(sys.argv) > 1 and sys.argv[1] == "--stats":
        try:
            processor = AlertProcessor()
            stats = processor.get_stats()
            stats["version"] = ALERT_PROCESSOR_VERSION
            print(json.dumps(stats, indent=2))
            return
        except Exception as e:
            print(json.dumps({"error": str(e), "version": ALERT_PROCESSOR_VERSION}))
            return

    processor = AlertProcessor()

    try:
        await processor.start()
    except KeyboardInterrupt:
        logger.info("Shutting down Alert Processor...")
    finally:
        processor.stop()

        # Print final statistics
        stats = processor.get_stats()
        print("\n" + "=" * 60)
        print("ðŸ“Š ALERT PROCESSOR FINAL STATISTICS")
        print("=" * 60)
        print(f"   Uptime: {stats['uptime_seconds']:.0f} seconds")
        print(f"   Alerts Processed: {stats['alerts_processed']}")
        print(f"   Alerts Delivered: {stats['alerts_sent']}")
        print(f"   Alerts Failed: {stats['alerts_failed']}")
        print(f"   Success Rate: {stats['success_rate']:.1f}%")
        print(f"   Deduplicated: {stats['alerts_deduplicated']}")
        print(f"   Rate Limited: {stats['alerts_rate_limited']}")
        print(f"   Dead Lettered: {stats['alerts_dead_lettered']}")
        print(f"   Retries Attempted: {stats['retries_attempted']}")
        print(f"   Processing Rate: {stats['alerts_per_minute']:.2f}/min")
        print("=" * 60)
        print("Queue Sizes:")
        for queue_name, size in stats["queue_sizes"].items():
            print(f"   {queue_name}: {size}")
        print("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())
